{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import traceback\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetCFG:\n",
    "    data_root = 'ml-25m'\n",
    "    num_negatives = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取训练数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensDataset(Dataset):\n",
    "    '''\n",
    "        ratings_data: userId|user_behavior|rating|movieId|title|genres\n",
    "    '''\n",
    "\n",
    "    def __init__(self, ratings_data, mode='train'):\n",
    "        self.user_ids, self.user_behaviors, self.movie_ids, self.movie_titles, self.movie_genres, self.labels = self.generate_dataset(\n",
    "            ratings_data, mode)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.user_ids[index], self.user_behaviors[index], self.movie_ids[index], self.movie_titles[index], self.movie_genres[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def generate_dataset(self, ratings_data, mode='train'):\n",
    "        movie_id_title_genres_list = list(\n",
    "            set(zip(ratings_data['movieId'], ratings_data['title'], ratings_data['genres'])))\n",
    "\n",
    "        user_item_set = set(\n",
    "            zip(ratings_data['userId'], ratings_data['movieId']))\n",
    "        user_ids, user_behaviors, movie_ids, movie_titles, movie_genres, labels = [], [], [], [], [], []\n",
    "        for rating in ratings_data.itertuples():\n",
    "            user_id = getattr(rating, 'userId')\n",
    "            user_behavior = getattr(rating, 'user_behavior')\n",
    "            movie_id = getattr(rating, 'movieId')\n",
    "            movie_title = getattr(rating, 'title')\n",
    "            movie_genre = getattr(rating, 'genres')\n",
    "            if mode == 'train':\n",
    "                for _ in range(DatasetCFG.num_negatives):\n",
    "                    negative_movie = random.choice(movie_id_title_genres_list)\n",
    "                    while (user_id, negative_movie[0]) in user_item_set:\n",
    "                        negative_movie = random.choice(\n",
    "                            movie_id_title_genres_list)\n",
    "                    user_ids.append(str(user_id))\n",
    "                    user_behaviors.append(user_behavior)\n",
    "                    movie_ids.append(str(negative_movie[0]))\n",
    "                    movie_titles.append(negative_movie[1])\n",
    "                    movie_genres.append(negative_movie[2])\n",
    "                    labels.append(0)\n",
    "            user_ids.append(str(user_id))\n",
    "            user_behaviors.append(user_behavior)\n",
    "            movie_ids.append(str(movie_id))\n",
    "            movie_titles.append(movie_title)\n",
    "            movie_genres.append(movie_genre)\n",
    "            labels.append(1)\n",
    "        return user_ids, user_behaviors, movie_ids, movie_titles, movie_genres, labels\n",
    "\n",
    "\n",
    "def spilt_train_test(file_name='ratings_data_process_0001.csv'):\n",
    "    ratings_data = pd.read_csv(os.path.join(\n",
    "        DatasetCFG.data_root, file_name))\n",
    "    ratings_train = ratings_data[ratings_data['rank_latest'] != ratings_data.groupby(\n",
    "        'userId')['rank_latest'].transform('max')]\n",
    "    ratings_test = ratings_data[ratings_data['rank_latest'] == ratings_data.groupby(\n",
    "        'userId')['rank_latest'].transform('max')]\n",
    "    return ratings_train, ratings_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(Net, self).__init__()\n",
    "        self.device = device\n",
    "        self.embedding = SentenceTransformer(\n",
    "            'models/all_datasets_v4_MiniLM-L6')\n",
    "        for param in self.embedding.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.user_fc1 = nn.Linear(384*2, 512)\n",
    "        self.user_fc2 = nn.Linear(512, 128)\n",
    "        self.movie_fc1 = nn.Linear(384*3, 512)\n",
    "        self.movie_fc2 = nn.Linear(512, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, user_id, user_behavior, movie_id, movie_title, movie_genre):\n",
    "        # display(user_id,user_behavior,movie_id,movie_title,movie_genre)\n",
    "        user_id_embedding = torch.tensor(\n",
    "            self.embedding.encode(user_id)).requires_grad_(True)\n",
    "        user_behavior_embedding = torch.tensor(\n",
    "            self.embedding.encode(user_behavior)).requires_grad_(True)\n",
    "        movie_id_embedding = torch.tensor(self.embedding.encode(\n",
    "            movie_id), requires_grad=True).requires_grad_(True)\n",
    "        movie_title_embedding = torch.tensor(self.embedding.encode(\n",
    "            movie_title), requires_grad=True).requires_grad_(True)\n",
    "        movie_genre_embedding = torch.tensor(self.embedding.encode(\n",
    "            movie_genre), requires_grad=True).requires_grad_(True)\n",
    "        # display(user_id_embedding.shape,user_behavior_embedding.shape,movie_id_embedding.shape,movie_title_embedding.shape,movie_genre_embedding.shape)\n",
    "\n",
    "        user_embedding = torch.cat(\n",
    "            [user_id_embedding, user_behavior_embedding], dim=1)\n",
    "        movie_embedding = torch.cat(\n",
    "            [movie_id_embedding, movie_title_embedding, movie_genre_embedding], dim=1)\n",
    "\n",
    "        user_embedding = user_embedding.to(self.device)\n",
    "        movie_embedding = movie_embedding.to(self.device)\n",
    "\n",
    "        user_out = self.user_fc1(user_embedding)\n",
    "        user_out = self.relu(user_out)\n",
    "        user_out = self.user_fc2(user_out)\n",
    "\n",
    "        movie_out = self.movie_fc1(movie_embedding)\n",
    "        movie_out = self.relu(movie_out)\n",
    "        movie_out = self.movie_fc2(movie_out)\n",
    "\n",
    "        result = user_out*movie_out\n",
    "        result = F.softmax(torch.sum(result, dim=1))\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_dataloader, epochs, device):\n",
    "    net.train()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "    for epoch in range(epochs):\n",
    "        for user_id, user_behavior, movie_id, movie_title, movie_genre, labels in tqdm(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(user_id, user_behavior, movie_id,\n",
    "                          movie_title, movie_genre)\n",
    "            labels = labels.to(device)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('epoch %d loss: %.3f' % (epoch + 1, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1453 [00:00<?, ?it/s]/tmp/ipykernel_1233041/2334235300.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(label).float().to(device)\n",
      "/tmp/ipykernel_1233041/1496312560.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = F.softmax(torch.sum(result, dim=1))\n",
      "100%|██████████| 1453/1453 [01:48<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0,loss:0.4366406798362732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1453/1453 [01:36<00:00, 15.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1,loss:0.5300308465957642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1453/1453 [01:43<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2,loss:0.37444034218788147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1453/1453 [01:43<00:00, 13.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3,loss:0.4988362789154053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1453/1453 [01:44<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4,loss:0.4366995096206665\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "ratings_train, ratings_test = spilt_train_test('ratings_data_process_0001.csv')\n",
    "train_dataset = MovieLensDataset(ratings_train, mode='train')\n",
    "test_dataset = MovieLensDataset(ratings_test, mode='test')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "model = Net(device)\n",
    "optimizer = torch.optim.SGD(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(5):\n",
    "    for batch in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "        user_id, user_behavior, movie_id, movie_title, movie_genre, label = batch\n",
    "        label = torch.tensor(label).float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(user_id, user_behavior, movie_id, movie_title, movie_genre)\n",
    "        loss = criterion(out, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"epoch:{},loss:{}\".format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:43<00:00, 232.26it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = SentenceTransformer('models/all_datasets_v4_MiniLM-L6')\n",
    "for _ in tqdm(range(10000)):\n",
    "    text1 = 'dsadsad sdasdasdas dsadas'\n",
    "    encode1 = torch.tensor(model.encode(text1, device=device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
