{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetCFG:\n",
    "    data_root='ml-25m'\n",
    "    user_chosen_num=1000\n",
    "    num_negatives=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取训练数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensDataset(Dataset):\n",
    "    '''\n",
    "        ratings_data: userId|user_behavior|rating|movieId|title|genres\n",
    "    '''\n",
    "    def __init__(self,ratings_data,mode='train'):        \n",
    "        self.user_ids,self.user_behaviors,self.movie_ids,self.movie_titles,self.movie_genres,self.labels=self.generate_dataset(ratings_data,mode)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return super().__getitem__(index)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "    \n",
    "    def generate_dataset(self,ratings_data,mode='train'):\n",
    "        user_ids,user_behaviors,movie_ids,movie_titles,movie_genres,labels=[],[],[],[],[],[]\n",
    "        for rating in ratings_data.itertuples():\n",
    "            user_id=getattr(rating,'userId')\n",
    "            user_behavior=getattr(rating,'user_behavior')\n",
    "            movie_id=getattr(rating,'movieId')\n",
    "            movie_title=getattr(rating,'title')\n",
    "            movie_genre=getattr(rating,'genres')\n",
    "            if mode=='train':\n",
    "                for _ in range(DatasetCFG.num_negatives):\n",
    "                    user_ids.append(user_id)\n",
    "                    user_behaviors.append(user_behavior)\n",
    "                    movie_ids.append(movie_id)\n",
    "                    movie_titles.append(movie_title)\n",
    "                    movie_genres.append(movie_genre)\n",
    "                    labels.append(0)\n",
    "            user_ids.append(user_id)\n",
    "            user_behaviors.append(user_behavior)\n",
    "            movie_ids.append(movie_id)\n",
    "            movie_titles.append(movie_title)\n",
    "            movie_genres.append(movie_genre)\n",
    "            labels.append(1)\n",
    "        return user_ids,user_behaviors,movie_ids,movie_titles,movie_genres,labels\n",
    "\n",
    "\n",
    "def data_preprocess():\n",
    "    ratings_path=os.path.join(DatasetCFG.data_root,'ratings.csv')\n",
    "    movies_path=os.path.join(DatasetCFG.data_root,'movies.csv')\n",
    "    ratings_data=pd.read_csv(ratings_path)\n",
    "    movies_data=pd.read_csv(movies_path)\n",
    "    \n",
    "    # random_user_ids=np.random.choice(ratings_data['userId'].unique(), \n",
    "    #                             size=int(len(ratings_data['userId'].unique())*0.001), \n",
    "    #                             replace=False)\n",
    "    # ratings_data=ratings_data[ratings_data['userId'].isin(random_user_ids)]      \n",
    "\n",
    "\n",
    "    ratings_data=ratings_data.merge(movies_data,on='movieId')\n",
    "    ratings_data['rank_latest'] = ratings_data.groupby(['userId'])['timestamp'].rank(method='first', ascending=True)\n",
    "    \n",
    "    ratings_data=ratings_data.sort_values(['userId','rank_latest'],ascending=[True,False]).reset_index(drop=True)\n",
    "    \n",
    "    for _, group in tqdm(ratings_data.groupby('userId'),total=len(ratings_data['userId'].unique())):\n",
    "        user_behavior_list = []\n",
    "        for _, row in group.iterrows():\n",
    "            user_behavior=\" \".join(map(str,group[group['rank_latest'] < row['rank_latest']]['movieId'].to_list()))\n",
    "            if user_behavior=='':\n",
    "                user_behavior=' '\n",
    "            user_behavior_list.append(user_behavior)\n",
    "        ratings_data.loc[group.index,'user_behavior'] = user_behavior_list\n",
    "        \n",
    "    ratings_data.to_csv(os.path.join(DatasetCFG.data_root,'ratings_data_process_1.csv'),index=False)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,device):\n",
    "        self.device = device\n",
    "        self.embeddings =SentenceTransformer('models/all_datasets_v4_MiniLM-L6')\n",
    "        self.user_fc1=nn.Linear(384*2,512)\n",
    "        self.user_fc2=nn.Linear(512,256)\n",
    "        \n",
    "        self.movie_fc1=nn.Linear(384*3,512)\n",
    "        self.movie_fc2=nn.Linear(512,256)\n",
    "        self.relu=nn.ReLU()\n",
    "        \n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self,user_id,user_behavior,movie_id,movie_title,movie_genre):\n",
    "        user_id_embedding=torch.tensor(self.embeddings.encode(str(user_id)))\n",
    "        user_behavior_embedding=torch.tensor(self.embeddings.encode(\" \".join(user_behavior)))\n",
    "        movie_id_embedding=torch.tensor(self.embeddings.encode(str(movie_id)))\n",
    "        movie_title_embedding=torch.tensor(self.embeddings.encode(movie_title))\n",
    "        movie_genre_embedding=torch.stack([torch.tensor(self.embeddings.encode(x)) for x  in movie_genre]).mean(dim=0)\n",
    "        \n",
    "        user_embedding=torch.cat([user_id_embedding,user_behavior_embedding],dim=0)\n",
    "        movie_embedding=torch.cat([movie_id_embedding,movie_title_embedding,movie_genre_embedding],dim=0)\n",
    "        user_embedding=user_embedding.to(self.device)\n",
    "        movie_embedding=movie_embedding.to(self.device)\n",
    "        \n",
    "        user_out=self.user_fc1(user_embedding)\n",
    "        user_out=self.relu(user_out)\n",
    "        user_out=self.user_fc2(user_out)\n",
    "        \n",
    "        movie_out=self.movie_fc1(movie_embedding)\n",
    "        movie_out=self.relu(movie_out)\n",
    "        movie_out=self.movie_fc2(movie_out)\n",
    "        \n",
    "        return torch.matmul(user_out,movie_out.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/162541 [00:00<?, ?it/s]/tmp/ipykernel_50957/865609639.py:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['296 7318 5684 27193 3569 5269 32591 8327 27266 2573 665 5767 5912 8729 1217 2632 4325 8405 7938 7937 7820 8685 7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '7318 5684 27193 3569 5269 32591 8327 27266 2573 665 5767 5912 8729 1217 2632 4325 8405 7938 7937 7820 8685 7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '5684 27193 3569 5269 32591 8327 27266 2573 665 5767 5912 8729 1217 2632 4325 8405 7938 7937 7820 8685 7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '27193 3569 5269 32591 8327 27266 2573 665 5767 5912 8729 1217 2632 4325 8405 7938 7937 7820 8685 7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '3569 5269 32591 8327 27266 2573 665 5767 5912 8729 1217 2632 4325 8405 7938 7937 7820 8685 7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '5269 32591 8327 27266 2573 665 5767 5912 8729 1217 2632 4325 8405 7938 7937 7820 8685 7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '32591 8327 27266 2573 665 5767 5912 8729 1217 2632 4325 8405 7938 7937 7820 8685 7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '8327 27266 2573 665 5767 5912 8729 1217 2632 4325 8405 7938 7937 7820 8685 7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '27266 2573 665 5767 5912 8729 1217 2632 4325 8405 7938 7937 7820 8685 7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '2573 665 5767 5912 8729 1217 2632 4325 8405 7938 7937 7820 8685 7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '665 5767 5912 8729 1217 2632 4325 8405 7938 7937 7820 8685 7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '5767 5912 8729 1217 2632 4325 8405 7938 7937 7820 8685 7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '5912 8729 1217 2632 4325 8405 7938 7937 7820 8685 7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '8729 1217 2632 4325 8405 7938 7937 7820 8685 7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '1217 2632 4325 8405 7938 7937 7820 8685 7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '2632 4325 8405 7938 7937 7820 8685 7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '4325 8405 7938 7937 7820 8685 7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '8405 7938 7937 7820 8685 7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '7938 7937 7820 8685 7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '7937 7820 8685 7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '7820 8685 7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '8685 7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '7209 7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '7940 2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '2351 1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '1260 8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '8786 5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '5147 31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '31956 4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '4703 8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '8973 6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '6370 7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '7939 8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '8014 6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '6954 7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '7323 27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '27721 2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '2692 8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '8873 6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '6016 4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '4973 4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '4422 2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '2068 7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '7365 4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '4144 2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '2843 7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '7234 8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '8154 7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '7327 1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '1237 307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '307 1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '1175 306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '306 5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '5878 8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '8360 3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '3949 6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '6711 2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '2161 4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '4308 899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '899 1088 3448 6377 6539 1250 1653 2011 2012 5952', '1088 3448 6377 6539 1250 1653 2011 2012 5952', '3448 6377 6539 1250 1653 2011 2012 5952', '6377 6539 1250 1653 2011 2012 5952', '6539 1250 1653 2011 2012 5952', '1250 1653 2011 2012 5952', '1653 2011 2012 5952', '2011 2012 5952', '2012 5952', '5952', ' ']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  ratings_data.loc[group.index,'user_behavior'] = user_behavior_list\n",
      "100%|██████████| 162541/162541 [2:13:41<00:00, 20.26it/s]   \n"
     ]
    }
   ],
   "source": [
    "data_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=SentenceTransformer('models/all_datasets_v4_MiniLM-L6')\n",
    "text1='12 2 3 4 5 6'\n",
    "encode1=torch.tensor(model.encode(text1))\n",
    "# display(encode1)\n",
    "text2='1 2 3 4 5 6'\n",
    "encode2=torch.tensor(model.encode(text2))\n",
    "c=torch.stack([encode1,encode2]).mean(dim=0)\n",
    "display(c.shape)\n",
    "# display(torch.cat([encode1,encode2],dim=0))\n",
    "\n",
    "# display(F.cosine_similarity(encode1,encode2,dim=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
